{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question 1</h1>\n",
    "\n",
    "You're given a dataset of products, categories, and their prices.\n",
    " Your task is to rank products by price within each category and classify them as:\n",
    "\n",
    "ðŸŸ¢ \"Price Up\" if the price is higher than the previous product in that category\n",
    "\n",
    "ðŸ”´ \"Price Down\" if the price is lower\n",
    "\n",
    "âšª \"Stable\" if the price is the same or it's the first product in that category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 22:51:00 WARN Utils: Your hostname, Yashs-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.3.100 instead (on interface en0)\n",
      "25/04/22 22:51:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/22 22:51:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/22 22:51:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"question_1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    " (\"ProductA\", \"Electronics\", 1000),\n",
    " (\"ProductB\", \"Electronics\", 1200),\n",
    " (\"ProductC\", \"Electronics\", 1100),\n",
    " (\"ProductD\", \"Clothing\", 50),\n",
    " (\"ProductE\", \"Clothing\", 40),\n",
    " (\"ProductF\", \"Clothing\", 50),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = [\"product\", \"category\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.partitionBy(\"category\").orderBy(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_lag = df.withColumn(\"previous_price\",lag(\"price\").over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----+--------------+\n",
      "| product|   category|price|previous_price|\n",
      "+--------+-----------+-----+--------------+\n",
      "|ProductE|   Clothing|   40|          NULL|\n",
      "|ProductD|   Clothing|   50|            40|\n",
      "|ProductF|   Clothing|   50|            50|\n",
      "|ProductA|Electronics| 1000|          NULL|\n",
      "|ProductC|Electronics| 1100|          1000|\n",
      "|ProductB|Electronics| 1200|          1100|\n",
      "+--------+-----------+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_lag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rank_df = df_with_lag.withColumn(\"price_trend\",\n",
    "                                       when(col(\"previous_price\").isNull(),\"stable\").\n",
    "                                       when(col(\"price\") > col(\"previous_price\"),\"price_up\").\n",
    "                                       when(col(\"price\") < col(\"previous_price\"),\"price_up\").\n",
    "                                       otherwise(\"stable\")\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----+--------------+-----------+\n",
      "| product|   category|price|previous_price|price_trend|\n",
      "+--------+-----------+-----+--------------+-----------+\n",
      "|ProductE|   Clothing|   40|          NULL|     stable|\n",
      "|ProductD|   Clothing|   50|            40|   price_up|\n",
      "|ProductF|   Clothing|   50|            50|     stable|\n",
      "|ProductA|Electronics| 1000|          NULL|     stable|\n",
      "|ProductC|Electronics| 1100|          1000|   price_up|\n",
      "|ProductB|Electronics| 1200|          1100|   price_up|\n",
      "+--------+-----------+-----+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_rank_df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
